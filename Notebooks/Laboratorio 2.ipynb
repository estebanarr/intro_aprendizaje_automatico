{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio 2: Armado de un esquema de aprendizaje automático\n",
    "\n",
    "En el laboratorio final se espera que puedan poner en práctica los conocimientos adquiridos en el curso, trabajando con un conjunto de datos de clasificación.\n",
    "\n",
    "El objetivo es que se introduzcan en el desarrollo de un esquema para hacer tareas de aprendizaje automático: selección de un modelo, ajuste de hiperparámetros y evaluación.\n",
    "\n",
    "El conjunto de datos a utilizar está en `./data/loan_data.csv`. Si abren el archivo verán que al principio (las líneas que empiezan con `#`) describen el conjunto de datos y sus atributos (incluyendo el atributo de etiqueta o clase).\n",
    "\n",
    "Se espera que hagan uso de las herramientas vistas en el curso. Se espera que hagan uso especialmente de las herramientas brindadas por `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TODO: Agregar las librerías que hagan falta\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos y división en entrenamiento y evaluación\n",
    "\n",
    "La celda siguiente se encarga de la carga de datos (haciendo uso de pandas). Estos serán los que se trabajarán en el resto del laboratorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../data/loan_data.csv\", comment=\"#\")\n",
    "\n",
    "# División entre instancias y etiquetas\n",
    "X, y = dataset.iloc[:, 1:], dataset.TARGET\n",
    "\n",
    "# división entre entrenamiento y evaluación\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Documentación:\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Descripción de los Datos y la Tarea\n",
    "\n",
    "Responder las siguientes preguntas:\n",
    "\n",
    "1. ¿De qué se trata el conjunto de datos?\n",
    "2. ¿Cuál es la variable objetivo que hay que predecir? ¿Qué significado tiene?\n",
    "3. ¿Qué información (atributos) hay disponible para hacer la predicción?\n",
    "4. ¿Qué atributos imagina ud. que son los más determinantes para la predicción?\n",
    "\n",
    "**No hace falta escribir código para responder estas preguntas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.TARGET.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Los datos están estructurados en una serie de variables obtenidas de clientes del departamento de créditos de un banco. Proporcionan datos relevantes sobre el desempeño de 5960 préstamos con garantía hipotecaria, categorizando los mismos según hayan caído en default o no. \n",
    "\n",
    "2) La variable objetivo a predecir `TARGET` es binaria y etiqueta aquellos prestamos que han sido pagados y los que no(default). El valor 0 se corresponde con aquellos que han pagado el préstamo, mientras que si toma valor 1 es porque han incumplido.\n",
    "\n",
    "3) Para cada solicitante de préstamo se registraron 12 variables de entrada o atributos que se mencionan a continuación.\n",
    "\n",
    "  \n",
    " `LOAN`: Monto de la solicitud de préstamo\n",
    " \n",
    " `MORTDUE`: Monto adeudado de la hipoteca existente\n",
    " \n",
    " `VALUE`: Valor de la propiedad actual\n",
    " \n",
    " `YOJ`: Años en el trabajo actual\n",
    " \n",
    " `DEROG`: Número de informes importantes derogados \n",
    " \n",
    " `DELINQ`: Número de líneas de crédito morosas\n",
    " \n",
    " `CLAGE`: Antigüedad de la línea comercial más antigua en meses\n",
    " \n",
    " `NINQ`: Número de líneas de crédito recientes\n",
    " \n",
    " `CLNO`: Número de líneas de crédito\n",
    " \n",
    "`DEBTINC`: Relación deuda-ingresos\n",
    "\n",
    "4) Los atributos más determinantes para la predicción son: `LOAN`,  `MORTDUE`, `DELINQ` y `DEBTINC`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Predicción con Modelos Lineales\n",
    "\n",
    "En este ejercicio se entrenarán modelos lineales de clasificación para predecir la variable objetivo.\n",
    "\n",
    "Para ello, deberán utilizar la clase SGDClassifier de scikit-learn.\n",
    "\n",
    "Documentación:\n",
    "- https://scikit-learn.org/stable/modules/sgd.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.1: SGDClassifier con hiperparámetros por defecto\n",
    "\n",
    "Entrenar y evaluar el clasificador SGDClassifier usando los valores por omisión de scikit-learn para todos los parámetros. Únicamente **fijar la semilla aleatoria** para hacer repetible el experimento.\n",
    "\n",
    "Evaluar sobre el conjunto de **entrenamiento** y sobre el conjunto de **evaluación**, reportando:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(dataset.TARGET)\n",
    "plt.title(\"Variable TARGET\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable objetivo esta muy desbalanceada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajustamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDClassifier(random_state=0)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predecimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred= model.predict(X_train)\n",
    "y_test_pred= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtención de métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "print(f'Train accuracy: {train_acc:0.2}')\n",
    "print(f'Test accuracy: {test_acc:0.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_precision=precision_score(y_train, y_train_pred) \n",
    "test_precision=precision_score(y_test, y_test_pred)\n",
    "print(f'Train precision: {train_precision:0.2}')\n",
    "print(f'Test precision: {test_precision:0.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_recall=recall_score(y_train, y_train_pred) \n",
    "test_recall=recall_score(y_test, y_test_pred)\n",
    "print(f'Train recall: {train_recall:0.2}')\n",
    "print(f'Test recall: {test_recall:0.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f1=f1_score(y_train, y_train_pred)\n",
    "test_f1=f1_score(y_test, y_test_pred)\n",
    "print(f'Train f1 score: {train_f1:0.2}')\n",
    "print(f'Test fi score: {test_f1:0.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sistematizamos todas las métricas en un cuadro\n",
    "y_train_pred= model.predict(X_train)\n",
    "y_test_pred= model.predict(X_test)\n",
    "\n",
    "print(\"ENTRENAMIENTO\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "print(\"TESTEO\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,y_pred_test)\n",
    "\n",
    "sns.heatmap(cm, annot=True)\n",
    "\n",
    "plt.title(\"Confusion matrix\")       #Esta matriz es rara, indicaría que no hay casos en que el label sea negativo?\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2.2: Ajuste de Hiperparámetros\n",
    "\n",
    "Seleccionar valores para los hiperparámetros principales del SGDClassifier. Como mínimo, probar diferentes funciones de loss, tasas de entrenamiento y tasas de regularización.\n",
    "\n",
    "Para ello, usar grid-search y 5-fold cross-validation sobre el conjunto de entrenamiento para explorar muchas combinaciones posibles de valores.\n",
    "\n",
    "Reportar accuracy promedio y varianza para todas las configuraciones.\n",
    "\n",
    "Para la mejor configuración encontrada, evaluar sobre el conjunto de **entrenamiento** y sobre el conjunto de **evaluación**, reportando:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- matriz de confusión\n",
    "\n",
    "Documentación:\n",
    "- https://scikit-learn.org/stable/modules/grid_search.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Coment FC: no lo quise borrar por las dudas se pierda algo importante, pero me parece que queda más claro como está desarrollado a partir de la celda de abajo\n",
    "\"\"\"\"\n",
    "params={'loss':['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "        'alpha':[0.1,0.01,0.001,0.0001],\n",
    "        'learning_rate': ['optimal','constant','invscaling','adaptive'],\n",
    "        'eta0': [0.01,0.001,0.0001]}\n",
    "\n",
    "grid=GridSearchCV(classifier,param_grid=params,cv=5,n_jobs=-1,scoring='accuracy',refit=True)\n",
    "\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "print(\"El mejor es: %f con %s\" % (grid.best_score_, grid.best_params_))\n",
    "means_acc= grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']\n",
    "for mean, stdev, param in zip(means_acc, stds, params):\n",
    "    print(\"%f (%f) con: %r\" % (mean, stdev, param))\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definimos una grilla de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'loss':['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "        'alpha':[0.1,0.01,0.001,0.0001],\n",
    "        'learning_rate': ['optimal','constant','invscaling','adaptive'],\n",
    "        'eta0': [0.01,0.001,0.0001]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hacemos la validación cruzada con el modelo de descenso de gradiente y la grilla de hiperparámetros que queremos probar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDClassifier(random_state=0)\n",
    "\n",
    "cv = GridSearchCV(model, params, scoring='accuracy', cv=5,refit=True)\n",
    "cv.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df[['param_loss', 'param_alpha', \"param_learning_rate\",'mean_test_score', 'std_test_score', 'rank_test_score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluamos, predecimos y obtenemos las métricas del mejor modelo obtenido a partir de los datos de entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model=SGDClassifier(alpha=0.1, eta0=0.01, learning_rate='constant', loss='squared_hinge',\n",
    "              random_state=0)\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_best= best_model.predict(X_train)\n",
    "y_test_pred_best= best_model.predict(X_test)\n",
    "\n",
    "print(\"ENTRENAMIENTO\")\n",
    "print(classification_report(y_train, y_train_pred_best))\n",
    "\n",
    "print(\"TESTEO\")\n",
    "print(classification_report(y_test, y_test_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,y_test_pred_best)\n",
    "\n",
    "sns.heatmap(cm, annot=True)\n",
    "\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se reajustó el modelo para una variedad de combinaciones de valores específicos para cada uno de los hiperparámetros. Se ajustaron 239 modelos diferentes, y se identificó el mejor modelo a aquel que tiene los siguientes parámetros:\n",
    "\n",
    "- alpha': 0.1,\n",
    "- 'eta0': 0.01,\n",
    "- 'learning_rate': 'constant',\n",
    "- 'loss': 'squared_hinge'\n",
    "\n",
    "Este modelo, presentó una accuracy promedio de 0.83333."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En comparación con el modelo estimado empleando los parámetros por default, podríamos decir que los resultados que obtenemos son los mismos. \n",
    "\n",
    "**FC: Esto tiene sentido? Justo los parámetros del mejor modelo coinciden con los definidos por default o hay algo mal?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGDClassifier??   #para comprobar que los parámetros por default no son los mismos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Árboles de Decisión\n",
    "\n",
    "En este ejercicio se entrenarán árboles de decisión para predecir la variable objetivo.\n",
    "\n",
    "Para ello, deberán utilizar la clase DecisionTreeClassifier de scikit-learn.\n",
    "\n",
    "Documentación:\n",
    "- https://scikit-learn.org/stable/modules/tree.html\n",
    "  - https://scikit-learn.org/stable/modules/tree.html#tips-on-practical-use\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "- https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3.1: DecisionTreeClassifier con hiperparámetros por defecto\n",
    "\n",
    "Entrenar y evaluar el clasificador DecisionTreeClassifier usando los valores por omisión de scikit-learn para todos los parámetros. Únicamente **fijar la semilla aleatoria** para hacer repetible el experimento.\n",
    "\n",
    "Evaluar sobre el conjunto de **entrenamiento** y sobre el conjunto de **evaluación**, reportando:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- matriz de confusión\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajustamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=DecisionTreeClassifier(random_state=0) \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predecimos y obtenemos las métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred= model.predict(X_train)\n",
    "y_test_pred=model.predict(X_test)\n",
    "\n",
    "print(\"ENTRENAMIENTO\")\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "print(\"TESTEO\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,y_test_pred)\n",
    "\n",
    "sns.heatmap(cm, annot=True)\n",
    "\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3.2: Ajuste de Hiperparámetros\n",
    "\n",
    "Seleccionar valores para los hiperparámetros principales del DecisionTreeClassifier. Como mínimo, probar diferentes criterios de partición (criterion), profundidad máxima del árbol (max_depth), y cantidad mínima de samples por hoja (min_samples_leaf).\n",
    "\n",
    "Para ello, usar grid-search y 5-fold cross-validation sobre el conjunto de entrenamiento para explorar muchas combinaciones posibles de valores.\n",
    "\n",
    "Reportar accuracy promedio y varianza para todas las configuraciones.\n",
    "\n",
    "Para la mejor configuración encontrada, evaluar sobre el conjunto de **entrenamiento** y sobre el conjunto de **evaluación**, reportando:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1\n",
    "- matriz de confusión\n",
    "\n",
    "\n",
    "Documentación:\n",
    "- https://scikit-learn.org/stable/modules/grid_search.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definimos una grilla de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    'max_depth': [2, 4, 15],\n",
    "    \"min_samples_leaf\": [5, 10, 20]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hacemos la validación cruzada con el modelo de descenso de árbol de desición y la grilla de hiperparámetros que queremos probar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "cv = GridSearchCV(model, param_grid, scoring='accuracy', cv=5)\n",
    "cv.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df[['param_criterion', 'param_max_depth', \"param_min_samples_leaf\",'mean_test_score', 'std_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluamos, predecimos y obtenemos las métricas del mejor modelo obtenido a partir de los datos de entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model=DecisionTreeClassifier(criterion=\"gini\", max_depth=4, min_samples_leaf=10, random_state=0)\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_best= best_model.predict(X_train)\n",
    "y_test_pred_best= best_model.predict(X_test)\n",
    "\n",
    "print(\"ENTRENAMIENTO\")\n",
    "print(classification_report(y_train, y_train_pred_best))\n",
    "\n",
    "print(\"TESTEO\")\n",
    "print(classification_report(y_test, y_test_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,y_test_pred_best)\n",
    "\n",
    "sns.heatmap(cm, annot=True)\n",
    "\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(best_model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODIFICAR\n",
    "Se reajustó el modelo para una variedad de combinaciones de valores específicos para cada uno de los hiperparámetros. Se ajustaron 17 modelos diferentes, y se identificó el mejor modelo a aquel que tiene los siguientes parámetros:\n",
    "\n",
    "\n",
    "- 'criterion': 'gini', \n",
    "- 'max_depth': 4, \n",
    "- 'min_samples_leaf': 10\n",
    "\n",
    "Este modelo, presentó una accuracy promedio de 0.89."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En comparación con el modelo estimado empleando los parámetros por default, podríamos decir que la accuracy promedio del conjunto de test mejora solo levemente. \n",
    "En cuanto a las otras métricas, el mejor modelo encontrado presenta ... \n",
    "**(FC: tengo dudas sobre la comparación entre las métricas, cuál debería mirar?)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
